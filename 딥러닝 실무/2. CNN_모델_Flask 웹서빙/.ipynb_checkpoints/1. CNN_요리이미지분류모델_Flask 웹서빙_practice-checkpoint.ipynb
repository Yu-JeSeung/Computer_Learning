{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4046881e",
   "metadata": {},
   "source": [
    "# CNN 요리이미지 분류 모델 웹 서빙"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b0c68",
   "metadata": {},
   "source": [
    "## Flask 서버 구성\n",
    "- app.py\n",
    "- cnn_model.py\n",
    "- photos-cnn-model.h5\n",
    "- templates\n",
    "    - index.html\n",
    "- static\n",
    "    - uploads\n",
    "        - test-salad.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf8eb4",
   "metadata": {},
   "source": [
    "### 1) index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<head>\n",
    "    <meta charset=\"utf8\">\n",
    "    <title>CNN 모델 웹서빙</title>\n",
    "    <style>\n",
    "\thtml { \n",
    "\t\tfont-size: 20px; \n",
    "                         font-weight: bold; \n",
    "             }\n",
    "            img {\n",
    "                         float: left;\n",
    "                         width: 40%;\n",
    "                         height: 50%;\n",
    "\t\tmargin: 5px;\n",
    "\t\tpadding: 5px;\n",
    "                         border: 2px solid #90C;\n",
    "            }\n",
    "            p    {\n",
    "                         clear: both;\n",
    "            }\n",
    "    </style>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "    <h1>CNN 모델로 요리 이미지 분류</h1>\n",
    "    <h2>이미지 업로드 및 CNN 예측</h2>\n",
    "    <hr>\n",
    "    {% if filename %}<br>\n",
    "        <div>\n",
    "            <img src=\"{{filename}}\" width=500 height=450 align=left>\n",
    "        </div>   \n",
    "        <br>       \n",
    "         <p>예측 : {{label}} &nbsp;&nbsp;  정확도 : {{probability}} &nbsp;&nbsp; 칼로리 : {{cal}}</p>          \n",
    "     {% endif %}\n",
    "\n",
    "    <form method=\"post\" action=\"/upload\" enctype=\"multipart/form-data\">\n",
    "        <input type=\"file\" name=\"file\">\n",
    "        <input type=\"submit\" value=\"submit\">\n",
    "    </form>\n",
    "    </div>\n",
    "</body>\n",
    "</head>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ce4d9",
   "metadata": {},
   "source": [
    "### 2) app.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2be577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [14/Apr/2022 21:30:19] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Apr/2022 21:30:19] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/test-salad.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002530786E048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002530786E048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:30:28] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.6554692e-06 9.9999130e-01 1.4691944e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:30:28] \"GET /static/uploads/test-salad.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/test-salad2.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025307A61C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025307A61C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:30:46] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.274306e-17 1.000000e+00 7.577807e-28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:30:46] \"GET /static/uploads/test-salad2.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/test-sushi2.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025307AB3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025307AB3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:31:38] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.952915e-01 4.708540e-03 5.124056e-19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:31:38] \"GET /static/uploads/test-sushi2.jpg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Apr/2022 21:34:45] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Apr/2022 21:34:46] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/tofu3.JPG\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025307A8B948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025307A8B948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:38:35] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1407698e-12 1.6197414e-13 1.0000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:38:36] \"GET /static/uploads/tofu3.JPG HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/test-salad3.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000253082E04C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000253082E04C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:39:30] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8075436e-22 1.0000000e+00 1.3820968e-28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:39:31] \"GET /static/uploads/test-salad3.jpg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Apr/2022 21:42:01] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Apr/2022 21:42:07] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Apr/2022 21:42:08] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/Screenshot_20211206-075430_Instagram.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000253082E0C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000253082E0C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:43:08] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.6123630e-01 3.8763758e-02 3.0744403e-09]\n",
      "/static/uploads/Screenshot_20211206-075430_Instagram.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000253082E04C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000253082E04C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[9.6123630e-01 3.8763758e-02 3.0744403e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:43:12] \"POST /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Apr/2022 21:43:13] \"GET /static/uploads/Screenshot_20211206-075430_Instagram.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/20220405_182321.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025308459C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025308459C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:44:29] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.5020419e-01 4.9795754e-02 5.4554175e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:44:29] \"GET /static/uploads/20220405_182321.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/20211022_131717.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025308459828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025308459828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:45:26] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8381119e-01 8.1618845e-01 2.4607425e-07]\n",
      "/static/uploads/20211022_131717.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000253084948B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000253084948B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:45:29] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8381119e-01 8.1618845e-01 2.4607425e-07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:45:30] \"GET /static/uploads/20211022_131717.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/uploads/20220206_195250.jpg\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002530A61F798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002530A61F798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:46:18] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.8077637e-01 1.9222768e-02 8.0487399e-07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2022 21:46:19] \"GET /static/uploads/20220206_195250.jpg HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import cnn_model\n",
    "from flask import Flask, render_template, request, session, escape, jsonify\n",
    "import requests\n",
    "import json, os\n",
    "from flask import *\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# 테스트 이미지 변형을 위한 변수 선언\n",
    "im_rows = 32 # 이미지의 높이\n",
    "im_cols = 32 # 이미지의 너비\n",
    "im_color = 3 # 이미지의 색공간\n",
    "in_shape = (im_rows, im_cols, im_color) # 입력 이미지 차원\n",
    "nb_classes = 3 # 클래스 수\n",
    "\n",
    "LABELS = [\"초밥\", \"샐러드\", \"마파두부\"] # 레이블 \n",
    "CALORIES = [588, 118, 648] # 각 레이블별 칼로리\n",
    "\n",
    "def solution(filename):    \n",
    "    # 학습된 CNN 모델과 가중치 불러오기\n",
    "    model = load_model('./photos-cnn-model.h5')\n",
    "    model.load_weights('./photos-cnn-weight.hdf5')\n",
    "    \n",
    "    # 이미지 읽어 들이기\n",
    "    print(filename)\n",
    "    img = Image.open(\"./\"+filename)\n",
    "    img = img.convert(\"RGB\") # 색공간 변환하기\n",
    "    img = img.resize((im_cols, im_rows)) # 크기 변경하기\n",
    "    \n",
    "    # 3차원으로 데이터 변환하기\n",
    "    x = np.asarray(img)\n",
    "    x = x.reshape(-1, im_rows, im_cols, im_color)\n",
    "    x = x / 255\n",
    "    \n",
    "    # 예측하기\n",
    "    pre = model.predict([x])[0]\n",
    "    print(pre)\n",
    "    idx = pre.argmax()\n",
    "    per = round(float(pre[idx] * 100),3)\n",
    "    \n",
    "    return idx, per\n",
    "\n",
    "# app 서버 \n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['UPLOAD_FOLDER'] = 'static/uploads'\n",
    "\n",
    "@app.route('/')\n",
    "@app.route('/index')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/upload', methods = ['POST'])\n",
    "def upload():\n",
    "    \n",
    "    file = request.files['file']\n",
    "    filename = file.filename\n",
    "    file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "    img_src = url_for('static', filename = 'uploads/' + filename)\n",
    "\n",
    "    label, prob = solution(img_src)\n",
    "    pred = LABELS[label] \n",
    "    cal = CALORIES[label] \n",
    "    cal = str(cal) + \"kcal\"\n",
    "    prob = str(round(prob, 2)) + \"%\"\n",
    "    \n",
    "    return render_template('index.html', filename=img_src, label=pred, probability=prob, cal=cal)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run('127.0.0.1', port=5000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00f014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de97e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
